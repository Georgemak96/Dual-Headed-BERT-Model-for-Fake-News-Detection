# Truth, Lies and Language Models: Detecting AI-Generated Fake News

In an era where generative AI can produce convincing news articles in seconds, distinguishing truth from fabrication has become more complex than ever. This project tackles the dual challenge of **misinformation detection** and **source attribution**—identifying not just whether a news article is fake, but whether it was written by a human or a language model.

## Project Overview

This research introduces a **dual-headed BERT-based classifier** trained on a diverse, multi-source dataset. The model simultaneously performs:
- **Fake vs Real classification**: Is the news factually accurate?
- **Human vs LLM classification**: Was it written by a person or generated by an AI?

By combining these tasks, the model offers a more nuanced understanding of modern misinformation, especially in contexts where AI-generated fake news is designed to mimic human writing styles.

## Model Experiments

### Dual-Head BERT (DistilBERT backbone)
- Multi-task classification: Fake-vs-Real and Human-vs-LLM
- Achieved **85% accuracy** on fake news detection and **96% accuracy** on LLM detection
- Strong generalization across unseen datasets and LLMs

### GPT-2 Fine-Tuning (Binary Fake News Classification)
In a parallel experiment, I fine-tuned **GPT-2** for binary fake news detection. Despite GPT-2 being designed for next-word prediction, it achieved surprisingly strong results:
- **87% accuracy** on fake news classification
- Performance close to BERT-based models

#### Why GPT-2 Worked Well
- Used the **last token of the final hidden state** as a proxy for BERT’s `[CLS]` token, leveraging masked attention to capture full-sequence context
- Applied **mean pooling** across all token embeddings
- Concatenated both representations and passed through a linear layer with sigmoid activation

This approach allowed GPT-2 to effectively summarize the input sequence and perform classification, even without native support for sequence-level tasks.

## Dataset Composition

- **Human-written sources**: Six datasets including real and fake news from verified outlets
- **LLM-generated sources**: Articles produced by GPT-3.5, Llama2, and Mistral across multiple prompts and strategies
- **MegaFake**: A challenging test set with highly realistic AI-generated fake news

## Results Summary

| Model              | Task               | Accuracy | F1 Score |
|-------------------|--------------------|----------|----------|
| Dual-Head BERT     | Fake vs Real       | 85%      | 86%      |
| Dual-Head BERT     | Human vs LLM       | 96%      | 85%      |
| GPT-2 Fine-Tuned   | Fake vs Real       | 87%      | ~87%     |
| BERT-Base (baseline)| Fake vs Real      | 89%      | ~90%     |

## Why It Matters

- **Scalable detection**: Works across multiple domains and writing styles
- **Future-proof**: Designed to adapt to evolving LLM capabilities
- **Real-world relevance**: Addresses urgent concerns in journalism, social media, and public discourse

Feel free to open an issue or reach out if you have questions, feedback, or ideas for improvement!
